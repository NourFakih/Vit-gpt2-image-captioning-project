{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1111676,
          "sourceType": "datasetVersion",
          "datasetId": 623289
        },
        {
          "sourceId": 1111749,
          "sourceType": "datasetVersion",
          "datasetId": 623329
        },
        {
          "sourceId": 1462296,
          "sourceType": "datasetVersion",
          "datasetId": 857191
        },
        {
          "sourceId": 8023465,
          "sourceType": "datasetVersion",
          "datasetId": 4728196
        },
        {
          "sourceId": 8023481,
          "sourceType": "datasetVersion",
          "datasetId": 4728207
        },
        {
          "sourceId": 8284832,
          "sourceType": "datasetVersion",
          "datasetId": 4920752
        },
        {
          "sourceId": 8285287,
          "sourceType": "datasetVersion",
          "datasetId": 4920953
        },
        {
          "sourceId": 172747871,
          "sourceType": "kernelVersion"
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Vit-image-captioning+coco+Flickr8k+30k",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NourFakih/Vit-gpt2-image-captioning-project/blob/main/Vit_image_captioning%2Bcoco%2BFlickr8k%2B30k.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'flickr8k:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F623289%2F1111676%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240503%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240503T095117Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0a58179cb13cfb4a6e8a41b05aba43b608e43ab114dab73844766fe088fdd1f2d860c123cb8853919dfcdbc50133f9a60cdf6b021db83b36a6e089d370c44a458b549935da1bcdf4eb7405698ebab1523d33879e4dcda96ee2d77247c083e641bb65127fab4ad23c0adf7021025290599eba5d88e0f9d00ca8170ad8d3eda16a81ba31d359384d779411ee5b34d90787c88226e855c3de1cc6e5b68572cfda93aaecbb769021165b5fb2052808fb55f43546217a58a5b26630c818f4df0bcba91090c2ed75722ea21b5d3851039a015dc02255cf036b90623e79c1cfb91a744bbe7a36afa70469fdae3903d7a4b16fc4f5741eb41b879d3c1425a58eed3c705b,flickr30k:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F623329%2F1111749%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240503%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240503T095117Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D2f4c9268c4e9e90b8c31750a5d96f94119e505ce6277f588110d6294704fa3943e1ca739fbc82038705a77620116852df69083bb10154b192582dd2ba5e2e6eddf5f150791761a0f72432179cf683f289afc20f8398dd6f5098dce1766dc01a57e5838f821b319a6fda97055ce0666dd49ea69f43a177c97c2571fd8677ce41eaa90214f5c9e5c0fed0ed98d52d52fb66a17daaec96f4b09a0d3b30b370a49df75301cc822d24c61fa588c604117b00b5a5ba5bb903fdb4e21501146313d1b8cea47d097d8aada92366828c2d89c69e178336ba1d8e7a52ea35bbd1a3198f95fa0e957a9cccc1c641ca8f1d3d10e1523700eac5f00674442c4e812bc3131f7ae,coco-2017-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F857191%2F1462296%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240503%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240503T095117Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D35e451c7fe6c5dac69c944bb48c309da04304c74fe57197a998a15211b7c85afc1e040390709548d2d5b9e7f6d02a9fec7fdbb704c46da0825225c422ed430a0fca996c7e4a1263ec6301af94bd31ea340399f354f9de7ef7208f5657d0df979afd5e2e45b19f2f1428536cb46da64a6b1d79544babc4a89aede2a7b323632f9228fa02b31d2890aaf59ce788a92dd83ea5009b0201f83d3a805a6277f3171aaa8df2a8553403de6e51e46236be980d5567a469a51699f1ef1b320ff69a08cb402b852f30f5bed6b24febf6594a04e4827a10ac0172e4e3fb48136bd10366f34d09077dbe667c18c14d2355f970aea11434252553af253b128b2011c8f35c174,images:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4728196%2F8023465%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240503%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240503T095117Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D621d8279b8f705fd0deab940bdf862fb609bf68200c1eab71802da563215426b950a294965b63f318b88390773ea3f0a7013945a4ecce3bc949cbffc2cdb216f2b7b44dc551cc6194904814f8f8a086524e3a279f48d97dce8076cc38bc78621820f09369fce5c9b4a88e731b5e60a704c38c837163adf8d7f96ae3253de7b59fe7d2509d732911a910d67681da981a2afa0a35901426991fea95910a05d1daa11e4f208cfe05ba620726efbe3dd1a257e17a9f76f79fc875a0b3d54bcd138f779b7fbd229b88f2659d3f0ec95290a5d5fc1cd8b6fa2755425b51b05ee7a7c3f5426657179b0b3ea1f690dc5cdd06a3e91952ff3f01f6e6d375e1e8800f2aa7f,testing:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4728207%2F8023481%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240503%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240503T095117Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4353c89119bf0a897e10ec871c4e53b5d3fb93496da79f595e29cd2a9981d297dfdb10bb8c30a69f1f6b6ef713cacc9f6e7be4edbad8ccba31c01d8bc8807faaf1047b88a45d307667a67d455a728cfb651085fd1dd106959b56fd4c9ff187b5e42ab41233940e14526a1f536571e049d1f52b6433e08a06527a8562ab9ea20d141ee22b35a170a69c54861aa85cc8260ce18f8ae4dc1f2ec350811cb90bb42b2ce058b41188dc17e71b332633e3f252591d519d43a83ba78b61b43029c2456b94cd956c956dd32979c35975ef51601dcba27cd0ecd6f8f2e33ef901a07667ead716f644efaf02aeaab19016a4eefa902c29f54e510075cf6b2cfe1745a9bd70,testcode:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4920752%2F8284832%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240503%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240503T095117Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D345e776661e2beb4a9e93e2287eb37bacec9cb20255b9dd5882e46742b45b35fc758318a08451cadaca01dec026aefc4b24523f8ad2b981f4d89a719bdc3580e5338949348ff0eff5670faa0686ccbb433483c1196d3f521d28086323f3c2e530b68e8beda92aceeb0f9e1d871245c705f9d6212a2abd5b04b7c4d0ceb305c26999eb6c8d28effef0d5a5f74f2cc881031822d3f677aefc58dc04be529a746f07aebd75267e19eb23cbd8f50f3b7e94e1838424bc1ee3156f9b8efabff671e4bb3e6f44877a4840b262aedf6deb5f846738db5b023af8794acf1f30e2d58f1a71f73fccfc6a29361b609800842a7bbc0a8ccd5b4d2810824401e791132b6a849,dataset-script:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4920953%2F8285287%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240503%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240503T095117Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D37a202f50e91130aa049555d45d113439373f9d8509cbc9067c96e05704871b387d8360edd9d9bf875e5cc3cff0ff785719f5eff7670c03f064abc4552e862fff70fd97a36da7e38118c7c199efc47426215200d8214223a2180b2492d25a4cd12e0ef7bb93e1f82b17c8140c05477659c607451f7747e31baebd39c176b784c6f34cd9fd0302eaf8419c9d02ec2bb5a2aa192e542550e659a0d7755328a426856b5e336d1e6cd077234b2f02bc2a1da7702b79cea2c44af10cdcd251a34fb02046224ed691aaf0722643f973188b6562a44aa20145d05e06a4dbb8a04b2f6880e91f91f8f4a8676aaa07d5ef23458359a779fe9b8e9d613323e290759b1b181'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "CMH4jVu73ZC3"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "GyYo-TaXYvig",
        "execution": {
          "iopub.status.busy": "2024-04-30T23:36:42.409318Z",
          "iopub.status.idle": "2024-04-30T23:36:42.409644Z",
          "shell.execute_reply.started": "2024-04-30T23:36:42.409471Z",
          "shell.execute_reply": "2024-04-30T23:36:42.40949Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setup Gdrive file download extention\n",
        "!conda install -y gdown"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T23:36:42.410466Z",
          "iopub.status.idle": "2024-04-30T23:36:42.410794Z",
          "shell.execute_reply.started": "2024-04-30T23:36:42.410634Z",
          "shell.execute_reply": "2024-04-30T23:36:42.410648Z"
        },
        "trusted": true,
        "id": "b_uDUW453ZDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1_AP0E8BGgXwOJ9e9SpW9LYHzqKJEjZsn\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T23:36:42.4121Z",
          "iopub.status.idle": "2024-04-30T23:36:42.412449Z",
          "shell.execute_reply.started": "2024-04-30T23:36:42.412287Z",
          "shell.execute_reply": "2024-04-30T23:36:42.412302Z"
        },
        "trusted": true,
        "id": "kOaQCdDm3ZDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /kaggle/working/image-captioning-output-save.zip"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T23:36:42.413846Z",
          "iopub.status.idle": "2024-04-30T23:36:42.414194Z",
          "shell.execute_reply.started": "2024-04-30T23:36:42.414012Z",
          "shell.execute_reply": "2024-04-30T23:36:42.414026Z"
        },
        "trusted": true,
        "id": "ppPGxZuz3ZDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.remove('/kaggle/working/image-captioning-output-save.zip')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-30T23:36:42.415473Z",
          "iopub.status.idle": "2024-04-30T23:36:42.415783Z",
          "shell.execute_reply.started": "2024-04-30T23:36:42.415633Z",
          "shell.execute_reply": "2024-04-30T23:36:42.415645Z"
        },
        "trusted": true,
        "id": "pItUMK1b3ZDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "LUlQ1DxsauNl",
        "execution": {
          "iopub.status.busy": "2024-04-30T23:36:42.417075Z",
          "iopub.status.idle": "2024-04-30T23:36:42.417406Z",
          "shell.execute_reply.started": "2024-04-30T23:36:42.417248Z",
          "shell.execute_reply": "2024-04-30T23:36:42.417261Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Illustrated Image Captioning using transformers\n",
        "Contents\n",
        "Introduction\n",
        "Vision Encoder Decoder Architecture\n",
        "Initialize VisionEncoderDecoderModel\n",
        "Data Loading and Preparation\n",
        "Define seq2seq training arguments\n",
        "Define metric\n",
        "Training\n",
        "Inference\n",
        "References\n",
        "Cited as IntroductionPermalink\n",
        "Image captioning is the process of generating caption i.e. description from input image. It requires both Natural language processing as well as computer vision to generate the caption.\n",
        "\n",
        "The popular benchmarking dataset which has images and its caption are:\n",
        "\n",
        "Common Objects in Context (COCO). A collection of more than 120 thousand images with descriptions.\n",
        "Flickr 8K: A collection of 8 thousand described images taken from flickr.com.\n",
        "Flickr 30K: A collection of 30 thousand described images taken from flickr.com.\n",
        "Try trained model: https://huggingface.co/nlpconnect/vit-gpt2-image-captioning\n",
        "\n",
        "Image Vision Encoder Decoder ArchitecturePermalink Image\n",
        "\n",
        "The Vision Encoder Decoder Model can be used to initialize an image-to-text model with any pre-trained Transformer-based vision model as the encoder (e.g. ViT, BEiT, DeiT, Swin) and any pre-trained language model as the decoder (e.g. RoBERTa, GPT2, BERT, DistilBERT).\n",
        "\n",
        "Image captioning is an example, in which the encoder model is used to encode the image, after which an autoregressive language model i.e. the decoder model generates the caption."
      ],
      "metadata": {
        "id": "J38EhGTJW123"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T11:24:44.460464Z",
          "iopub.execute_input": "2024-05-01T11:24:44.460886Z",
          "iopub.status.idle": "2024-05-01T11:24:44.767798Z",
          "shell.execute_reply.started": "2024-05-01T11:24:44.46085Z",
          "shell.execute_reply": "2024-05-01T11:24:44.766905Z"
        },
        "trusted": true,
        "id": "KZr7_GVf3ZDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datasets\n",
        "from transformers import VisionEncoderDecoderModel, AutoFeatureExtractor,AutoTokenizer\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "qSTBTAmgW126",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:24:56.07921Z",
          "iopub.execute_input": "2024-05-01T11:24:56.079582Z",
          "iopub.status.idle": "2024-05-01T11:25:03.147193Z",
          "shell.execute_reply.started": "2024-05-01T11:24:56.079552Z",
          "shell.execute_reply": "2024-05-01T11:25:03.146145Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hvHLdHPF3ZDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "try:\n",
        "    nltk.data.find(\"tokenizers/punkt\")\n",
        "except (LookupError, OSError):\n",
        "    nltk.download(\"punkt\", quiet=True)"
      ],
      "metadata": {
        "id": "6hd80tQmW127",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:03.148877Z",
          "iopub.execute_input": "2024-05-01T11:25:03.149355Z",
          "iopub.status.idle": "2024-05-01T11:25:04.185179Z",
          "shell.execute_reply.started": "2024-05-01T11:25:03.149328Z",
          "shell.execute_reply": "2024-05-01T11:25:04.184214Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize VisionEncoderDecoderModel"
      ],
      "metadata": {
        "id": "KT_kw7I0W128"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import VisionEncoderDecoderModel, AutoTokenizer, AutoFeatureExtractor, ViTImageProcessor\n",
        "\n",
        "image_encoder_model = \"google/vit-base-patch16-224-in21k\"\n",
        "#image_encoder_model = \"google/vivit-b-16x2-kinetics400\"\n",
        "text_decode_model = \"gpt2\"\n",
        "\n",
        "#model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(image_encoder_model, text_decode_model)"
      ],
      "metadata": {
        "id": "WiEuGJu0W129",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:04.186464Z",
          "iopub.execute_input": "2024-05-01T11:25:04.18684Z",
          "iopub.status.idle": "2024-05-01T11:25:13.921242Z",
          "shell.execute_reply.started": "2024-05-01T11:25:04.186807Z",
          "shell.execute_reply": "2024-05-01T11:25:13.920195Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "feature_extractor = ViTImageProcessor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")"
      ],
      "metadata": {
        "id": "WsEm0-lNW12_",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:13.924398Z",
          "iopub.execute_input": "2024-05-01T11:25:13.924878Z",
          "iopub.status.idle": "2024-05-01T11:25:25.987254Z",
          "shell.execute_reply.started": "2024-05-01T11:25:13.924839Z",
          "shell.execute_reply": "2024-05-01T11:25:25.986243Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FeatureExtractor is used to extract features i.e. image patch resolution of 16x16.\n",
        "\n",
        "Tokenizer is used to tokenize and encode text features."
      ],
      "metadata": {
        "id": "jTYoBlrKW13B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import *\n",
        "# image feature extractor\n",
        "#feature_extractor = AutoFeatureExtractor.from_pretrained(image_encoder_model)\n",
        "#feature_extractor =ViTImageProcessor.from_pretrained(image_encoder_model)\n",
        "# text tokenizer\n",
        "#tokenizer = AutoTokenizer.from_pretrained(text_decode_model)"
      ],
      "metadata": {
        "id": "0EhkqR5WW13C",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:25.98865Z",
          "iopub.execute_input": "2024-05-01T11:25:25.9897Z",
          "iopub.status.idle": "2024-05-01T11:25:25.993858Z",
          "shell.execute_reply.started": "2024-05-01T11:25:25.989644Z",
          "shell.execute_reply": "2024-05-01T11:25:25.992858Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT2 only has bos/eos tokens but not decoder_start/pad tokens\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# update the model config\n",
        "model.config.eos_token_id = tokenizer.eos_token_id\n",
        "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "id": "g7gBKplVW13C",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:25.995083Z",
          "iopub.execute_input": "2024-05-01T11:25:25.995448Z",
          "iopub.status.idle": "2024-05-01T11:25:29.860049Z",
          "shell.execute_reply.started": "2024-05-01T11:25:25.995423Z",
          "shell.execute_reply": "2024-05-01T11:25:29.859008Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"vit-gpt-model\"\n",
        "model.save_pretrained(output_dir)\n",
        "feature_extractor.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "metadata": {
        "id": "S_xVZlt5W13D",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:29.861446Z",
          "iopub.execute_input": "2024-05-01T11:25:29.861742Z",
          "iopub.status.idle": "2024-05-01T11:25:31.425829Z",
          "shell.execute_reply.started": "2024-05-01T11:25:29.861719Z",
          "shell.execute_reply": "2024-05-01T11:25:31.424862Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading and PreparationPermalink\n",
        "We are going to use sample dataset from ydshieh/coco_dataset_script.\n",
        "\n",
        "For using Full COCO dataset (2017), you need to download it manually first:"
      ],
      "metadata": {
        "id": "CTmtZScdW13D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#wget http://images.cocodataset.org/zips/train2017.zip\n",
        "#wget http://images.cocodataset.org/zips/val2017.zip\n",
        "#wget http://images.cocodataset.org/zips/test2017.zip\n",
        "#wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "#wget http://images.cocodataset.org/annotations/image_info_test2017.zip Then to load the dataset:\n",
        "\n",
        "#COCO_DIR = \"/kaggle/input/coco-2017-dataset\"\n",
        "#ds = datasets.load_dataset(\"/kaggle/input/coco-2017-dataset\",\"2017\", data_dir=COCO_DIR)\n",
        "#COCO_DIR = \"/kaggle/input/coco-2017-dataset\"\n",
        "\n",
        "# Load the COCO2017 dataset using the correct path\n",
        "#ds = datasets.load_dataset(\"coco\", \"2017\", data_dir=COCO_DIR)"
      ],
      "metadata": {
        "id": "O2EuD2JUW13E",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:31.427194Z",
          "iopub.execute_input": "2024-05-01T11:25:31.427832Z",
          "iopub.status.idle": "2024-05-01T11:25:31.432704Z",
          "shell.execute_reply.started": "2024-05-01T11:25:31.427796Z",
          "shell.execute_reply": "2024-05-01T11:25:31.431606Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5KwSTUEBW13E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LzbyMtcWW13E",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2OarPpaYW13F",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "ds = datasets.load_dataset(\"ydshieh/coco_dataset_script\", \"2017\", data_dir=\"./dummy_data/\")\n",
        "ds"
      ],
      "metadata": {
        "id": "FY4Y9srwW13F",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:31.434163Z",
          "iopub.execute_input": "2024-05-01T11:25:31.434408Z",
          "iopub.status.idle": "2024-05-01T11:25:35.801069Z",
          "shell.execute_reply.started": "2024-05-01T11:25:31.434387Z",
          "shell.execute_reply": "2024-05-01T11:25:35.800139Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import datasets\n",
        "#ds = datasets.load_dataset(\"/kaggle/input/coco-2017-dataset/coco2017\", \"default\", data_dir=\"./annotations\", field='./annotations')\n",
        "    #ds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:35.805463Z",
          "iopub.execute_input": "2024-05-01T11:25:35.80591Z",
          "iopub.status.idle": "2024-05-01T11:25:35.810471Z",
          "shell.execute_reply.started": "2024-05-01T11:25:35.805878Z",
          "shell.execute_reply": "2024-05-01T11:25:35.809093Z"
        },
        "trusted": true,
        "id": "FO1iTGOY3ZDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print single example\n",
        "ds['train'][1]"
      ],
      "metadata": {
        "id": "IyH8Jad1W13F",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:35.812276Z",
          "iopub.execute_input": "2024-05-01T11:25:35.812601Z",
          "iopub.status.idle": "2024-05-01T11:25:35.829545Z",
          "shell.execute_reply.started": "2024-05-01T11:25:35.812573Z",
          "shell.execute_reply": "2024-05-01T11:25:35.828645Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# text preprocessing step\n",
        "def tokenization_fn(captions, max_target_length):\n",
        "    \"\"\"Run tokenization on captions.\"\"\"\n",
        "    labels = tokenizer(captions,\n",
        "                      padding=\"max_length\",\n",
        "                      max_length=max_target_length).input_ids\n",
        "\n",
        "    return labels\n",
        "\n",
        "# image preprocessing step\n",
        "def feature_extraction_fn(image_paths, check_image=True):\n",
        "    \"\"\"\n",
        "    Run feature extraction on images\n",
        "    If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n",
        "    Otherwise, an exception will be thrown.\n",
        "    \"\"\"\n",
        "\n",
        "    model_inputs = {}\n",
        "\n",
        "    if check_image:\n",
        "        images = []\n",
        "        to_keep = []\n",
        "        for image_file in image_paths:\n",
        "            try:\n",
        "                img = Image.open(image_file)\n",
        "                images.append(img)\n",
        "                to_keep.append(True)\n",
        "            except Exception:\n",
        "                to_keep.append(False)\n",
        "    else:\n",
        "        images = [Image.open(image_file) for image_file in image_paths]\n",
        "\n",
        "    encoder_inputs = feature_extractor(images=images, return_tensors=\"np\")\n",
        "\n",
        "    return encoder_inputs.pixel_values\n",
        "\n",
        "def preprocess_fn(examples, max_target_length, check_image = True):\n",
        "    \"\"\"Run tokenization + image feature extraction\"\"\"\n",
        "    image_paths = examples['image_path']\n",
        "    captions = examples['caption']\n",
        "\n",
        "    model_inputs = {}\n",
        "    # This contains image path column\n",
        "    model_inputs['labels'] = tokenization_fn(captions, max_target_length)\n",
        "    model_inputs['pixel_values'] = feature_extraction_fn(image_paths, check_image=check_image)\n",
        "\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "SaITCmFGW13F",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:35.830644Z",
          "iopub.execute_input": "2024-05-01T11:25:35.83097Z",
          "iopub.status.idle": "2024-05-01T11:25:35.840871Z",
          "shell.execute_reply.started": "2024-05-01T11:25:35.830945Z",
          "shell.execute_reply": "2024-05-01T11:25:35.839891Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PIL for Flickr8k"
      ],
      "metadata": {
        "id": "TUjd7dz6W13G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processed_dataset = ds.map(\n",
        "    function=preprocess_fn,\n",
        "    batched=True,\n",
        "    fn_kwargs={\"max_target_length\": 128},\n",
        "    remove_columns=ds['train'].column_names\n",
        ")"
      ],
      "metadata": {
        "id": "3IuAdEZxW13G",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:35.842051Z",
          "iopub.execute_input": "2024-05-01T11:25:35.842368Z",
          "iopub.status.idle": "2024-05-01T11:25:38.091595Z",
          "shell.execute_reply.started": "2024-05-01T11:25:35.842338Z",
          "shell.execute_reply": "2024-05-01T11:25:38.090709Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_dataset"
      ],
      "metadata": {
        "id": "drK6mfKQW13G",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:38.092953Z",
          "iopub.execute_input": "2024-05-01T11:25:38.093415Z",
          "iopub.status.idle": "2024-05-01T11:25:38.099815Z",
          "shell.execute_reply.started": "2024-05-01T11:25:38.093377Z",
          "shell.execute_reply": "2024-05-01T11:25:38.09879Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define seq2seq training argumentsPermalink"
      ],
      "metadata": {
        "id": "JpTm9m0rW13G"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UaFoRrz3AMef",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import TrainingArguments\n",
        "\n",
        "#args = TrainingArguments(\"working_dir\")\n",
        "#args = args.set_evaluate(strategy=\"steps\", steps=100)\n",
        "#args.eval_steps"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:38.101005Z",
          "iopub.execute_input": "2024-05-01T11:25:38.101278Z",
          "iopub.status.idle": "2024-05-01T11:25:38.453207Z",
          "shell.execute_reply.started": "2024-05-01T11:25:38.101256Z",
          "shell.execute_reply": "2024-05-01T11:25:38.452291Z"
        },
        "trusted": true,
        "id": "YoHVmlWz3ZDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Lj8aEPYU3ZDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    #save_strategy=\"epoch\",\n",
        "    #evaluation_strategy=\"epoch\",\n",
        "    #steps=1000,\n",
        "    #save_steps=100,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    output_dir=\"./image-captioning-Vit-GPT2-Flickr8k\",\n",
        "    overwrite_output_dir=True,\n",
        "    #evaluation_strategy=\"steps\",\n",
        "    save_total_limit=3,\n",
        "    load_best_model_at_end=True,\n",
        "    #tpu_num_cores\n",
        "    #accelerator_config (str, dict, or AcceleratorConfig, optional),\n",
        "    push_to_hub=True,\n",
        "    #resume_from_checkpoint=/kaggle/working/image-captioning-Vit-GPT2-Flickr8k/checkpoint-3000,\n",
        "    #hub_token=,\n",
        "    hub_always_push=True,\n",
        ")"
      ],
      "metadata": {
        "id": "jOGLxQm5W13G",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:38.454412Z",
          "iopub.execute_input": "2024-05-01T11:25:38.454735Z",
          "iopub.status.idle": "2024-05-01T11:25:38.588984Z",
          "shell.execute_reply.started": "2024-05-01T11:25:38.454696Z",
          "shell.execute_reply": "2024-05-01T11:25:38.588155Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Metric"
      ],
      "metadata": {
        "id": "ngluZ4ZJW13G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "TbV5NDG0W13H",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:38.590055Z",
          "iopub.execute_input": "2024-05-01T11:25:38.590342Z",
          "iopub.status.idle": "2024-05-01T11:25:52.729739Z",
          "shell.execute_reply.started": "2024-05-01T11:25:38.590316Z",
          "shell.execute_reply": "2024-05-01T11:25:52.728739Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "B2EiV2PaW13H",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:25:52.731355Z",
          "iopub.execute_input": "2024-05-01T11:25:52.732245Z",
          "iopub.status.idle": "2024-05-01T11:26:07.297736Z",
          "shell.execute_reply.started": "2024-05-01T11:25:52.732201Z",
          "shell.execute_reply": "2024-05-01T11:26:07.296587Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "metric = evaluate.load(\"rouge\")"
      ],
      "metadata": {
        "id": "w6Z74PY8W13H",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:26:07.299292Z",
          "iopub.execute_input": "2024-05-01T11:26:07.299625Z",
          "iopub.status.idle": "2024-05-01T11:26:08.4756Z",
          "shell.execute_reply.started": "2024-05-01T11:26:07.299593Z",
          "shell.execute_reply": "2024-05-01T11:26:08.474867Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "ignore_pad_token_for_loss = True\n",
        "\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [label.strip() for label in labels]\n",
        "\n",
        "    # rougeLSum expects newline after each sentence\n",
        "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
        "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    if ignore_pad_token_for_loss:\n",
        "        # Replace -100 in the labels as we can't decode them.\n",
        "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds,\n",
        "                                                     decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds,\n",
        "                            references=decoded_labels,\n",
        "                            use_stemmer=True)\n",
        "    result = {k: round(v * 100, 4) for k, v in result.items()}\n",
        "    prediction_lens = [\n",
        "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
        "    ]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    return result"
      ],
      "metadata": {
        "id": "14fTEd3GW13H",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:26:08.476554Z",
          "iopub.execute_input": "2024-05-01T11:26:08.476816Z",
          "iopub.status.idle": "2024-05-01T11:26:08.486572Z",
          "shell.execute_reply.started": "2024-05-01T11:26:08.476793Z",
          "shell.execute_reply": "2024-05-01T11:26:08.485718Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "Oui_EDJbW13I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QcdWjkPnW13I",
        "execution": {
          "iopub.status.busy": "2024-04-25T19:51:28.153355Z",
          "iopub.execute_input": "2024-04-25T19:51:28.154168Z",
          "iopub.status.idle": "2024-04-25T19:51:28.270635Z",
          "shell.execute_reply.started": "2024-04-25T19:51:28.154122Z",
          "shell.execute_reply": "2024-04-25T19:51:28.269514Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import default_data_collator\n",
        "\n",
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    tokenizer=feature_extractor,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=processed_dataset['train'],\n",
        "    eval_dataset=processed_dataset['validation'],\n",
        "    data_collator=default_data_collator,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T11:26:08.487612Z",
          "iopub.execute_input": "2024-05-01T11:26:08.487866Z",
          "iopub.status.idle": "2024-05-01T11:26:09.013732Z",
          "shell.execute_reply.started": "2024-05-01T11:26:08.487845Z",
          "shell.execute_reply": "2024-05-01T11:26:09.012717Z"
        },
        "trusted": true,
        "id": "Metsfdl53ZDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trainer.train()"
      ],
      "metadata": {
        "id": "PdTVqh-XW13J",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:26:09.015006Z",
          "iopub.execute_input": "2024-05-01T11:26:09.015346Z",
          "iopub.status.idle": "2024-05-01T11:26:09.019818Z",
          "shell.execute_reply.started": "2024-05-01T11:26:09.015314Z",
          "shell.execute_reply": "2024-05-01T11:26:09.018818Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DdBqn0km3ZDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# Load the CSV file containing image paths and captions\n",
        "csv_file_path = \"/kaggle/input/flickr8k/captions.txt\"\n",
        "df = pd.read_csv(csv_file_path)\n",
        "df[\"image\"] = \"/kaggle/input/flickr8k/Images/\" + df[\"image\"]\n",
        "# Limit df to 20,000 rows\n",
        "#df = df.head(5000)\n",
        "# Get the second part of the dataset (rows 10,000 to 20,000)\n",
        "#second_part_df = df.iloc[10000:20000]\n",
        "# Split the dataset into train, validation, and test sets\n",
        "train_size = int(0.8 * len(df))\n",
        "valid_size = int(0.1 * len(df))\n",
        "test_size = len(df) - train_size - valid_size\n",
        "\n",
        "train_df = df[:train_size]\n",
        "valid_df = df[train_size:train_size + valid_size]\n",
        "test_df = df[train_size + valid_size:]\n",
        "\n",
        "# Convert each split into a Dataset object\n",
        "train_data = Dataset.from_pandas(train_df)\n",
        "valid_data = Dataset.from_pandas(valid_df)\n",
        "test_data = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Organize the splits into a DatasetDict\n",
        "ds = DatasetDict({\n",
        "    \"train\": train_data,\n",
        "    \"validation\": valid_data,\n",
        "    \"test\": test_data\n",
        "})\n",
        "\n",
        "# Access the DatasetDict\n",
        "print(ds)\n",
        "test_data\n",
        "test_df"
      ],
      "metadata": {
        "id": "XXDpUZJDW13K",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:26:09.021174Z",
          "iopub.execute_input": "2024-05-01T11:26:09.021793Z",
          "iopub.status.idle": "2024-05-01T11:26:09.22563Z",
          "shell.execute_reply.started": "2024-05-01T11:26:09.021751Z",
          "shell.execute_reply": "2024-05-01T11:26:09.224684Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fFQ8I2X6cr4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "class ImageCapatioingDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, ds, ds_type, max_target_length):\n",
        "        self.ds = ds\n",
        "        self.max_target_length = max_target_length\n",
        "        self.ds_type = ds_type\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.ds[self.ds_type]['image'][idx]\n",
        "        caption = self.ds[self.ds_type]['caption'][idx]\n",
        "        model_inputs = dict()\n",
        "        model_inputs['labels'] = self.tokenization_fn(caption, self.max_target_length)\n",
        "        model_inputs['pixel_values'] = self.feature_extraction_fn(image_path)\n",
        "        return model_inputs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds[self.ds_type])\n",
        "\n",
        "    # text preprocessing step\n",
        "    def tokenization_fn(self, caption, max_target_length):\n",
        "        \"\"\"Run tokenization on caption.\"\"\"\n",
        "        labels = tokenizer(caption,\n",
        "                          padding=\"max_length\",\n",
        "                          max_length=max_target_length).input_ids\n",
        "\n",
        "        return labels\n",
        "\n",
        "    # image preprocessing step\n",
        "    def feature_extraction_fn(self, image_path):\n",
        "        \"\"\"\n",
        "        Run feature extraction on images\n",
        "        If `check_image` is `True`, the examples that fails during `Image.open()` will be caught and discarded.\n",
        "        Otherwise, an exception will be thrown.\n",
        "        \"\"\"\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        encoder_inputs = feature_extractor(images=image, return_tensors=\"np\")\n",
        "\n",
        "        return encoder_inputs.pixel_values[0]\n",
        "\n",
        "\n",
        "train_ds = ImageCapatioingDataset(ds, 'train', 64)\n",
        "eval_ds = ImageCapatioingDataset(ds, 'validation', 64)\n",
        "\n",
        "\n",
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    tokenizer=feature_extractor,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=eval_ds,\n",
        "    data_collator=default_data_collator,\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-01T11:26:09.226795Z",
          "iopub.execute_input": "2024-05-01T11:26:09.227066Z",
          "iopub.status.idle": "2024-05-01T11:26:09.338532Z",
          "shell.execute_reply.started": "2024-05-01T11:26:09.227042Z",
          "shell.execute_reply": "2024-05-01T11:26:09.337549Z"
        },
        "trusted": true,
        "id": "S3Sshujq3ZDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Cn2wkKShW13N",
        "execution": {
          "iopub.status.busy": "2024-05-01T11:26:09.339543Z",
          "iopub.execute_input": "2024-05-01T11:26:09.339829Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "XdedbTvl3ZDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./image-captioning-Vit-GPT2-Flickr8k\")"
      ],
      "metadata": {
        "id": "sQsFtPxdW13N",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"./image-captioning-Vit-GPT2-Flickr8k\")"
      ],
      "metadata": {
        "id": "K_ehUwmMW13O",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "WkNX3JzAW13O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "dzKwd9I2W13O",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full dataset trained model can be found at https://huggingface.co/nlpconnect/vit-gpt2-image-captioning\n",
        "image_captioner = pipeline(\"image-to-text\", model=\"./image-captioning-Vit-GPT2-Flickr8k\")"
      ],
      "metadata": {
        "id": "r_lJ1rBKW13T",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_captioner(\"/kaggle/input/testing/free-images.jpg\")"
      ],
      "metadata": {
        "id": "KTNg892yW13T",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_captioner(\"/kaggle/input/testing/nature-image-for-website.jpg\")"
      ],
      "metadata": {
        "id": "VpfKxxp_W13T",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_captioner(\"/kaggle/input/testing/Polish__.jpg\")"
      ],
      "metadata": {
        "id": "9iB1hL8gbciC",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r image-captioning-output-save.zip /kaggle/working/image-captioning-Vit-GPT2-Flickr8k\n"
      ],
      "metadata": {
        "id": "8gPCD-BfNzCi",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## from IPython.display import FileLink\n",
        "FileLink(r'image-captioning-output-save.zip')\n"
      ],
      "metadata": {
        "id": "p4Aa42MR3ZDm"
      }
    }
  ]
}